


# !pip install scikeras
# !pip install hyperas
# !conda install tensorflow-gpu





import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
sns.color_palette("colorblind")

import tensorflow as tf
from tensorflow	import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import layers
from tensorflow.keras import optimizers
from scikeras.wrappers import KerasRegressor, KerasClassifier

from sklearn.model_selection import train_test_split
# from sklearn.preprocessing import StandardScaler
# from sklearn.preprocessing import Normalizer
from sklearn.preprocessing import PowerTransformer
from sklearn.compose import ColumnTransformer
from sklearn.metrics import r2_score
from sklearn.model_selection import RepeatedKFold, RandomizedSearchCV, GridSearchCV
from sklearn.metrics import make_scorer, mean_squared_error, r2_score
from tensorflow.keras.models import load_model

import pickle

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' 


dtypes_dict = {
    'Serial No.' : int,
    'GRE Score' : int,
    'TOEFL Score' : int,
    'University Rating' : int,
    'SOP' : float,
    'LOR' : float,
    'CGPA' : float,
    'Research' : int,
    'Chance of Admit ' : float
}
# memory_map = True can lead to mixed inference of data types, therefore pass one extra argument of the dtypes
admissions_data = pd.read_csv("../data/admissions_data.csv", usecols=['CGPA','GRE Score', 'SOP', 'Research', 'Chance of Admit '], 
                              encoding='utf-8', dtype=dtypes_dict, memory_map=True, low_memory=True)
admissions_data.sample(5)


admissions_data.info()





features = admissions_data.iloc[:, :-1]
labels = admissions_data.iloc[:, -1]





# Select numerical features
numerical_features = features.select_dtypes(include=['int', 'float']).columns

# Initialize ColumnTransformer
ct = ColumnTransformer([("only numeric", PowerTransformer(), numerical_features)],
                       remainder='passthrough')

# Split data
features_train, features_test, labels_train, labels_test = train_test_split(features, labels,
                                                                            test_size=0.3, random_state=42)

# Fit and transform with ColumnTransformer
features_train_scaled = ct.fit_transform(features_train)
features_test_scaled = ct.transform(features_test)











class NeuralNetworkWithDropout:
    def __init__(self, input_shape, learning_rate=0.001, units=64, dropout_rate=0.2):
        self.input_shape = input_shape
        self.learning_rate = learning_rate
        self.units = units
        self.dropout_rate = dropout_rate
        self.model = self.build_model()

    def build_model(self):
        model = Sequential(name="log_reg_nn")
        model.add(tf.keras.Input(shape=self.input_shape))
        model.add(layers.Dense(self.units, activation='relu'))
        model.add(layers.Dropout(self.dropout_rate)) # https://keras.io/api/layers/regularization_layers/dropout/
        model.add(layers.BatchNormalization()) # https://keras.io/api/layers/normalization_layers/batch_normalization/
        model.add(layers.Dense(self.units, activation='relu'))
        model.add(layers.Dropout(self.dropout_rate))
        model.add(layers.BatchNormalization())
        model.add(layers.Dense(self.units, activation='relu'))
        model.add(layers.Dropout(self.dropout_rate))
        model.add(layers.BatchNormalization())
        model.add(layers.Dense(1, activation='sigmoid')) # arbitrary value between 0 and 1, thus only sigmoid
        
        opt = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)
        model.compile(loss='mse', metrics=['mae'], optimizer=opt)
        model.run_eagerly = False # disable eager execution of the model
        return model

    def get_keras_regressor(self):
        def model_builder(learning_rate=self.learning_rate, units=self.units, dropout_rate=self.dropout_rate):
            return self.build_model()
        
        return KerasRegressor(model=model_builder, verbose=0)


%%time

# define parameter grid for GridSearchCV
param_grid = {
    "model__units": [64, 128, 256],
    "model__learning_rate": np.arange(0.002, 0.011, 0.002),
    "model__dropout_rate": np.around(np.arange(0.0, 0.6, 0.1), decimals=2),
    "batch_size": [16, 32, 64, 128]
}

# using RepeatedKFold for iterated k-fold validation
rkf = RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)

# gridSearchCV setup
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, 
                           cv=rkf, verbose=1, n_jobs=2, scoring='neg_mean_absolute_error')

# fit GridSearchCV to the scaled training data
grid_result = grid_search.fit(features_train_scaled, labels_train)


# print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))

# Save results in a DataFrame for plotting later
# results_df = pd.DataFrame(grid_result.cv_results_)

# Save results to a CSV file (optional)
# os.makedirs("results/", exist_ok=True) # create results directory only if it doesn't exist
# results_df.to_csv('results/grid_search_results.csv', index=False)


best_params = grid_result.best_params_ # save the best parameters

# access through the best parameters individually the hyperparameters
best_units = best_params.get('model__units')  # number of neurons
best_lr = best_params.get('model__learning_rate')
best_dropout_rate = best_params.get('model__dropout_rate')
best_batch = best_params.get('batch_size')

best_model = design_model_dropout(best_lr, best_units, best_dropout_rate)

# instantiate early stopping to reduce training time if highest performance reached
early_stopping = EarlyStopping(
    monitor='val_loss',
    verbose=1,  
    patience=40,
    restore_best_weights=True,
    mode='auto',
)

history = best_model.fit(
    features_train_scaled,
    labels_train,
    verbose=0,
    epochs=500,
    batch_size=best_batch,
    validation_split=0.2,
    callbacks=[early_stopping],
)

# save the model
os.makedirs("../results/model/", exist_ok=True)
best_model.save('best_log_reg_nn.keras')


y_pred = best_model.predict(features_test_scaled)

print(f"y_pred shape: {y_pred.shape}")
print(f"labels_test shape: {labels_test.shape}")

# flatten y_pred if necessary
if y_pred.shape != labels_test.shape:
    y_pred = y_pred.reshape(-1)

# ensure y_pred and labels_test are the same shape
assert y_pred.shape == labels_test.shape, "Shape mismatch between predictions and actual labels after reshaping"

# calculate the R-squared value
r2 = r2_score(labels_test, y_pred)
print(f"R-squared value: {r2}")





os.makedirs("../results/plots/", exist_ok=True)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss: Mean Squared Error over Epochs')
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.legend(['train', 'test'])
plt.savefig("../results/plots/mse_epochs_learn_curve.png", dpi=500, format='png')
plt.show()


os.makedirs("../results/plots/", exist_ok=True)

plt.plot(history.history['mae'])
plt.plot(history.history['val_mae'])
plt.title('Model Loss: Mean Absolute Error over Epochs')
plt.ylabel('MAE')
plt.xlabel('Epochs')
plt.legend(['train', 'test'])
plt.savefig("../results/plots/mae_epochs_learn_curve.png", format='png', dpi=500)
plt.show()


os.makedirs("../results/history", exist_ok=True)
with open('../results/history/trainHistoryDict', 'wb') as file_pi:
    pickle.dump(history.history, file_pi)

print(history.history.keys())


# in case you want to read it and do something with that
# with open('results/history/trainHistoryDict', "rb") as file_pi:
#     history = pickle.load(file_pi)
